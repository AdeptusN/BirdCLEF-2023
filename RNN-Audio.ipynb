{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:33:54.521841Z","iopub.execute_input":"2023-04-13T09:33:54.522791Z","iopub.status.idle":"2023-04-13T09:34:05.249951Z","shell.execute_reply.started":"2023-04-13T09:33:54.522739Z","shell.execute_reply":"2023-04-13T09:34:05.248542Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchaudio\nfrom torchaudio.transforms import *\nfrom torchvision.transforms import Compose\n\nfrom tqdm import tqdm\nfrom torchsummary import summary\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:34:38.081582Z","iopub.execute_input":"2023-04-13T09:34:38.081945Z","iopub.status.idle":"2023-04-13T09:34:38.088745Z","shell.execute_reply.started":"2023-04-13T09:34:38.081913Z","shell.execute_reply":"2023-04-13T09:34:38.087629Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"labels = os.listdir(\"/kaggle/input/birdclef-2023/train_audio\")\nlabels = pd.Series(labels)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:33:05.677024Z","iopub.execute_input":"2023-04-13T09:33:05.677600Z","iopub.status.idle":"2023-04-13T09:33:05.708436Z","shell.execute_reply.started":"2023-04-13T09:33:05.677570Z","shell.execute_reply":"2023-04-13T09:33:05.707393Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class BirdRNNDataset(Dataset):\n    def __init__(self, root_dir, transforms=None):\n        super(BirdRNNDataset, self).__init__()\n        self.root_dir = root_dir\n        \n        self.labels = os.listdir(root_dir)\n        \n        self.len_labels = len(labels)\n        labels_ind = torch.arange(0, self.len_labels)\n        \n        self.targets = F.one_hot(labels_ind)\n        \n        self.items = [(label, elem) for label in labels \\\n                      for elem in os.listdir(os.path.join(root_dir, label))]\n        \n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.items)\n    \n    def __getitem__(self, index):\n        label, filename = self.items[index]\n        filepath = os.path.join(self.root_dir, label, filename)\n        \n        audio, _ = torchaudio.load(filepath)\n        audio = self.to_mono(audio)\n        \n        if self.transforms:\n            audio = transforms(audio)\n        \n        target_ind = self.labels.index(label)\n        target = self.targets[target_ind]\n        \n        return audio, target\n    \n        \n    def to_mono(self, audio):\n        return torch.mean(audio, axis=0)\n    \n    def labels_count(self):\n        return self.len_labels","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:33:05.710090Z","iopub.execute_input":"2023-04-13T09:33:05.710509Z","iopub.status.idle":"2023-04-13T09:33:05.720283Z","shell.execute_reply.started":"2023-04-13T09:33:05.710472Z","shell.execute_reply":"2023-04-13T09:33:05.719077Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def collate_batch(data):\n    inputs, labels = zip(*data)\n    max_length = max(inputs, key=lambda x: x.size()[1]).size()[1]\n    dim_size = inputs[0].size()[0]\n    \n    batch = torch.zeros(size=(len(data), dim_size, max_length))\n    for i, elem in enumerate(inputs):\n        batch[i] =  torch.cat([elem, torch.zeros(dim_size, max_length - elem.size()[1])], axis=1)\n    \n    batch = batch.transpose(1, 2)\n    targets = torch.stack(labels)\n    \n    return batch, targets","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:33:05.723370Z","iopub.execute_input":"2023-04-13T09:33:05.723830Z","iopub.status.idle":"2023-04-13T09:33:05.734026Z","shell.execute_reply.started":"2023-04-13T09:33:05.723792Z","shell.execute_reply":"2023-04-13T09:33:05.733072Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class BirdNet(nn.Module):\n    def __init__(self, n_mels, n_labels, bidirectional=False, hidden_size=600, lstm_dropout=0.):\n        super(BirdNet, self).__init__()\n        self.gru1 = nn.GRU(input_size=n_mels, hidden_size=hidden_size, batch_first=True, bidirectional=bidirectional)\n        self.gru2 = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, batch_first=True, bidirectional=bidirectional)\n        self.fc1 = nn.Linear(in_features=hidden_size, out_features=hidden_size//2)\n        self.fc2 = nn.Linear(in_features=hidden_size//2, out_features=n_labels)\n        \n        self.dropout=nn.Dropout()\n        self.relu = nn.ReLU()\n        \n        self.softmax = nn.Softmax()\n        \n    def forward(self, x):\n        output1, h_n = self.gru1(x)\n        rel1 = self.relu(output1)\n        \n        output2 = self.gru(rel1, h_n)\n        rel2 = self.rel(output2)\n        \n        dense1 = self.fc1(rel)\n        drop = self.dropout(dense1)\n        dense2 = self.fc2(drop)\n        #preds = self.softmax(dense2)\n        return dense2","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:33:05.736806Z","iopub.execute_input":"2023-04-13T09:33:05.737108Z","iopub.status.idle":"2023-04-13T09:33:05.748609Z","shell.execute_reply.started":"2023-04-13T09:33:05.737083Z","shell.execute_reply":"2023-04-13T09:33:05.747396Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = \"/kaggle/input/birdclef-2023/train_audio\"\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nresample_freq = 16000\nfreq_mask = 10\ntime_stretch_coeff = 0.8\nn_fft = 1024\nn_mels = 256\nhidden_size = 600\nbatch_size = 4\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:33:05.749977Z","iopub.execute_input":"2023-04-13T09:33:05.750778Z","iopub.status.idle":"2023-04-13T09:33:05.813068Z","shell.execute_reply.started":"2023-04-13T09:33:05.750732Z","shell.execute_reply":"2023-04-13T09:33:05.811883Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"transforms = Compose([\n    Resample(orig_freq=32000, new_freq=resample_freq),\n    Spectrogram(n_fft=n_fft, power=2.),\n    MelScale(n_mels=n_mels, n_stft=n_fft // 2 + 1, sample_rate=resample_freq)\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:33:05.814504Z","iopub.execute_input":"2023-04-13T09:33:05.815725Z","iopub.status.idle":"2023-04-13T09:33:05.938192Z","shell.execute_reply.started":"2023-04-13T09:33:05.815695Z","shell.execute_reply":"2023-04-13T09:33:05.937118Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchaudio/functional/functional.py:572: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n  \"At least one mel filterbank has all zero values. \"\n","output_type":"stream"}]},{"cell_type":"code","source":"ds = BirdRNNDataset(TRAIN_DIR, bidirectional=True, transforms=transforms)\ntrain_ds, val_ds = torch.utils.data.random_split(ds, [0.8, 0.2])\n\ntrain_dl = DataLoader(train_ds,\n                    batch_size=batch_size,\n                    collate_fn=collate_batch,\n                     )\n\nval_dl = DataLoader(val_ds,\n                    batch_size=batch_size,\n                    collate_fn=collate_batch,\n                   )","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:33:06.076482Z","iopub.execute_input":"2023-04-13T09:33:06.077065Z","iopub.status.idle":"2023-04-13T09:33:09.392432Z","shell.execute_reply.started":"2023-04-13T09:33:06.077028Z","shell.execute_reply":"2023-04-13T09:33:09.391410Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for audio, target in train_dl:\n    print(audio.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:33:09.394562Z","iopub.execute_input":"2023-04-13T09:33:09.394916Z","iopub.status.idle":"2023-04-13T09:33:09.862531Z","shell.execute_reply.started":"2023-04-13T09:33:09.394880Z","shell.execute_reply":"2023-04-13T09:33:09.861561Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"torch.Size([4, 2072, 256])\n","output_type":"stream"}]},{"cell_type":"code","source":"n_labels = ds.labels_count()\n\nmodel = BirdNet(n_mels=n_mels, hidden_size=hidden_size, n_labels=n_labels)\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss() \noptimizer = optim.Adam(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:34:54.949522Z","iopub.execute_input":"2023-04-13T09:34:54.950418Z","iopub.status.idle":"2023-04-13T09:34:58.448965Z","shell.execute_reply.started":"2023-04-13T09:34:54.950380Z","shell.execute_reply":"2023-04-13T09:34:58.447907Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"summary(model, (2072, 256))","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:35:47.884464Z","iopub.execute_input":"2023-04-13T09:35:47.885166Z","iopub.status.idle":"2023-04-13T09:35:49.662857Z","shell.execute_reply.started":"2023-04-13T09:35:47.885127Z","shell.execute_reply":"2023-04-13T09:35:49.661710Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n               GRU-1  [[-1, 2072, 600], [-1, 2, 600]]               0\n              ReLU-2            [-1, 2072, 600]               0\n            Linear-3            [-1, 2072, 300]         180,300\n           Dropout-4            [-1, 2072, 300]               0\n            Linear-5            [-1, 2072, 264]          79,464\n================================================================\nTotal params: 259,764\nTrainable params: 259,764\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 2.02\nForward/backward pass size (MB): 11358.69\nParams size (MB): 0.99\nEstimated Total Size (MB): 11361.71\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"n_epochs = 5\n\ntrain_history = []\nval_history = []\n\nfor epoch in range(n_epochs):\n    print(f'Epoch: {epoch + 1}')\n    train_epoch_history = []\n    val_epoch_history = []\n    \n    model.train()\n    for data, label in tqdm(train_dl):\n        data = data.to(device)\n        target = label.to(device)\n        \n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        train_epoch_history.append(loss.item())\n        \n    model.eval()\n    for data, label in tqdm(val_dl):\n        data = data.to(device)\n        target = label.to(device)\n        \n        output = model(data)\n        loss = criterion(output, target)\n        val_epoch_history.append(loss.item())\n    \n    train_average_loss = np.mean(train_epoch_history)\n    val_average_loss = np.mean(val_epoch_history)\n    train_history.append(train_average_loss)\n    val_history.append(val_average_loss)\n    print(f'train loss: {train_average_loss}')\n    print(f'val loss: {val_average_loss}')","metadata":{"execution":{"iopub.status.busy":"2023-04-08T13:43:22.569658Z","iopub.execute_input":"2023-04-08T13:43:22.570377Z","iopub.status.idle":"2023-04-08T17:28:33.722214Z","shell.execute_reply.started":"2023-04-08T13:43:22.570337Z","shell.execute_reply":"2023-04-08T17:28:33.721050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict, './output.pt')","metadata":{"execution":{"iopub.status.busy":"2023-04-08T17:35:24.532999Z","iopub.execute_input":"2023-04-08T17:35:24.534015Z","iopub.status.idle":"2023-04-08T17:35:24.559351Z","shell.execute_reply.started":"2023-04-08T17:35:24.533974Z","shell.execute_reply":"2023-04-08T17:35:24.557834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_history)\nplt.plot(val_history)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-08T17:36:22.174790Z","iopub.execute_input":"2023-04-08T17:36:22.175259Z","iopub.status.idle":"2023-04-08T17:36:22.513701Z","shell.execute_reply.started":"2023-04-08T17:36:22.175214Z","shell.execute_reply":"2023-04-08T17:36:22.512542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'output.pt')","metadata":{"execution":{"iopub.status.busy":"2023-04-08T17:40:12.543459Z","iopub.execute_input":"2023-04-08T17:40:12.544447Z","iopub.status.idle":"2023-04-08T17:40:12.552133Z","shell.execute_reply.started":"2023-04-08T17:40:12.544394Z","shell.execute_reply":"2023-04-08T17:40:12.551088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}